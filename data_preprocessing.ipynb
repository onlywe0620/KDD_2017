{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# concat training data & weath data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start data preparation\n"
     ]
    }
   ],
   "source": [
    "print ('start data preparation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d=pd.read_csv('./trajectories(table 5)_training.csv')\n",
    "d1=pd.read_csv('./trajectories(table_5)_training2.csv')\n",
    "w=pd.read_csv('./weather (table 7)_training_update.csv')\n",
    "w1=pd.read_csv('./weather (table 7)_test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.concat([d,d1],ignore_index=True)\n",
    "weath=pd.concat([w,w1],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['starting_time']=data['starting_time'].astype(np.datetime64)\n",
    "data['date']=data['starting_time'].dt.date\n",
    "data['month']=data['starting_time'].dt.month\n",
    "data['day']=data['starting_time'].dt.day\n",
    "data['hour']=data['starting_time'].dt.hour\n",
    "data['time']=data['starting_time'].dt.minute\n",
    "data['weekday']=data['starting_time'].dt.weekday+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop data of holiday\n",
    "c=data.loc[(data['month']==10)&(data['day']==10)|\n",
    "         ((data['month']==9)&(data['day']==29)&(data['hour']>=21))|\n",
    "         ((data['month']==9)&(data['day']==30)&(data['hour']<3))]\n",
    "data=data.drop(data.index[c.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#oversize data processing\n",
    "data.loc[data['travel_time']>=500,'travel_time']=500\n",
    "#data.loc[data['travel_time']>500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.to_csv('train_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let training data become 5 min step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avgTravelTime(in_file,path,out_suffix):\n",
    "    file_suffix = '.csv'\n",
    "    in_file_name = in_file + file_suffix\n",
    "    out_file_name = out_suffix + file_suffix\n",
    "\n",
    "    # Step 1: Load trajectories\n",
    "    fr = open(path + in_file_name, 'r')\n",
    "    fr.readline()  # skip the header\n",
    "    traj_data = fr.readlines()\n",
    "    fr.close()\n",
    "    print(traj_data[0])\n",
    "\n",
    "    # Step 2: Create a dictionary to store travel time for each route per time window\n",
    "    travel_times = {}  # key: route_id. Value is also a dictionary of which key is the start time for the time window and value is a list of travel times\n",
    "    for i in range(len(traj_data)):\n",
    "        each_traj = traj_data[i].replace('\"', '').split(',')\n",
    "        intersection_id = each_traj[0]\n",
    "        tollgate_id = each_traj[1]\n",
    "\n",
    "        route_id = intersection_id + '-' + tollgate_id\n",
    "        if route_id not in travel_times.keys():\n",
    "            travel_times[route_id] = {}\n",
    "\n",
    "        trace_start_time = each_traj[3]\n",
    "        trace_start_time = datetime.strptime(trace_start_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "        time_window_minute = math.floor(trace_start_time.minute / 5) * 5\n",
    "        start_time_window = datetime(trace_start_time.year, trace_start_time.month, trace_start_time.day,\n",
    "                                     int(trace_start_time.hour), int(time_window_minute), 0)\n",
    "        tt = float(each_traj[5]) # travel time\n",
    "\n",
    "        if start_time_window not in travel_times[route_id].keys():\n",
    "            travel_times[route_id][start_time_window] = [tt]\n",
    "        else:\n",
    "            travel_times[route_id][start_time_window].append(tt)\n",
    "\n",
    "    # Step 3: Calculate average travel time for each route per time window\n",
    "    fw = open(out_file_name, 'w')\n",
    "    fw.writelines(','.join(['\"intersection_id\"', '\"tollgate_id\"', '\"time_window\"', '\"avg_travel_time\"']) + '\\n')\n",
    "    for route in travel_times.keys():\n",
    "        route_time_windows = list(travel_times[route].keys())\n",
    "        route_time_windows.sort()\n",
    "        for time_window_start in route_time_windows:\n",
    "            time_window_end = time_window_start + timedelta(minutes=5)\n",
    "            tt_set = travel_times[route][time_window_start]\n",
    "            avg_tt = round(sum(tt_set) / float(len(tt_set)), 2)\n",
    "            out_line = ','.join(['\"' + route.split('-')[0] + '\"', '\"' + route.split('-')[1] + '\"',\n",
    "                                 '\"[' + str(time_window_start) + ',' + str(time_window_end) + ')\"',\n",
    "                                 '\"' + str(avg_tt) + '\"']) + '\\n'\n",
    "            fw.writelines(out_line)\n",
    "    fw.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B,3,1065642,2016-07-19 00:14:24,105#2016-07-19 00:14:24#9.56;100#2016-07-19 00:14:34#6.75;111#2016-07-19 00:14:41#13.00;103#2016-07-19 00:14:54#7.47;122#2016-07-19 00:15:02#32.85,70.85,2016-07-19,7,19,0,14,2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_file = 'train_data'\n",
    "path='./'\n",
    "out_suffix = '5min_avg_travel_time_training'\n",
    "avgTravelTime(in_file,path,out_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"A\",\"2\",\"1000775\",\"2016-10-25 06:00:15\",\"110#2016-10-25 06:00:15#10.52;123#2016-10-25 06:00:25#5.09;107#2016-10-25 06:00:30#2.93;108#2016-10-25 06:00:33#3.58;120#2016-10-25 06:00:37#0.79;117#2016-10-25 06:00:38#17.89\",\"40.89\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_file = 'trajectories(table 5)_test2'\n",
    "path='./'\n",
    "out_suffix = '5min_avg_travel_time_testing'\n",
    "avgTravelTime(in_file,path,out_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('5min_avg_travel_time_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for c in data['time_window']:\n",
    "    c1=datetime.strptime(c[1:20], \"%Y-%m-%d %H:%M:%S\")\n",
    "    a.append(c1)\n",
    "data['date']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['month']=data['date'].dt.month\n",
    "data['day']=data['date'].dt.day\n",
    "data['hour']=data['date'].dt.hour\n",
    "data['time']=data['date'].dt.minute\n",
    "data['weekday']=data['date'].dt.weekday+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.insert(3, \"t1\", 0)\n",
    "data.insert(4, \"t2\", 0)\n",
    "data.insert(5, \"t3\", 0)\n",
    "data.insert(6, \"deltat1\", 0)\n",
    "data.insert(7, \"deltat2\", 0)\n",
    "data.insert(15,\"pressure\", 0)\n",
    "data.insert(16,\"sea_pressure\", 0)\n",
    "data.insert(17,\"wind_direction\", 0)\n",
    "data.insert(18,\"wind_speed\", 0)\n",
    "data.insert(19,\"temperature\", 0)\n",
    "data.insert(20,\"rel_humidity\", 0)\n",
    "data.insert(21,\"precipitation\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A2=data.loc[(data['intersection_id']=='A')&(data['tollgate_id']==2)]\n",
    "A3=data.loc[(data['intersection_id']=='A')&(data['tollgate_id']==3)]\n",
    "B1=data.loc[(data['intersection_id']=='B')&(data['tollgate_id']==1)]\n",
    "B3=data.loc[(data['intersection_id']=='B')&(data['tollgate_id']==3)]\n",
    "C1=data.loc[(data['intersection_id']=='C')&(data['tollgate_id']==1)]\n",
    "C3=data.loc[(data['intersection_id']=='C')&(data['tollgate_id']==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d=[A2,A3,B1,B3,C1,C3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time1=timedelta(days=0,minutes=5)\n",
    "time2=timedelta(days=0,minutes=10)\n",
    "time3=timedelta(days=0,minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for data in d:\n",
    "    for c in (data.index):\n",
    "        data.loc[(data[\"date\"])==(data[\"date\"][c]+time1),'t1']=data[\"avg_travel_time\"][c]\n",
    "        data.loc[(data[\"date\"])==(data[\"date\"][c]+time2),'t2']=data[\"avg_travel_time\"][c]\n",
    "        data.loc[(data[\"date\"])==(data[\"date\"][c]+time3),'t3']=data[\"avg_travel_time\"][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data in d:\n",
    "    for c in range(7):\n",
    "        for c1 in range(24):\n",
    "            data.loc[(data['weekday']==c) & (data['hour']==c1) & (data['t1']==0),'t1']=data.loc[(data['weekday']==c) & (data['hour']==c1) & (data['t1']!=0)]['t1'].mean()\n",
    "            data.loc[(data['weekday']==c) & (data['hour']==c1) & (data['t2']==0),'t2']=data.loc[(data['weekday']==c) & (data['hour']==c1) & (data['t2']!=0)]['t2'].mean()\n",
    "            data.loc[(data['weekday']==c) & (data['hour']==c1) & (data['t3']==0),'t3']=data.loc[(data['weekday']==c) & (data['hour']==c1) & (data['t3']!=0)]['t3'].mean()\n",
    "    for c in range(7):\n",
    "        for c1 in range(24):\n",
    "            data.loc[(data['t1'].isnull())&(data['hour']==c1),'t1']=data.loc[(data['hour']==c1)&(data['weekday']!=c)]['t1'].mean()\n",
    "            data.loc[(data['t2'].isnull())&(data['hour']==c1),'t2']=data.loc[(data['hour']==c1)&(data['weekday']!=c)]['t2'].mean()\n",
    "            data.loc[(data['t3'].isnull())&(data['hour']==c1),'t3']=data.loc[(data['hour']==c1)&(data['weekday']!=c)]['t3'].mean()\n",
    "    for c in range(7):\n",
    "        for c1 in range(24):\n",
    "            data.loc[(data['t1'].isnull())&(data['hour']==c1) & (data['weekday']==c),'t1']=data.loc[(data['hour']==c1)&(data['weekday']==c)]['avg_travel_time'].mean()\n",
    "            data.loc[(data['t2'].isnull())&(data['hour']==c1) & (data['weekday']==c),'t2']=data.loc[(data['hour']==c1)&(data['weekday']==c)]['avg_travel_time'].mean()\n",
    "            data.loc[(data['t3'].isnull())&(data['hour']==c1) & (data['weekday']==c),'t3']=data.loc[(data['hour']==c1)&(data['weekday']==c)]['avg_travel_time'].mean()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.concat(d,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['deltat1']=data['t1']-data['t2']\n",
    "data['deltat2']=data['t2']-data['t3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# weather data processiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weath['date']=weath['date'].astype(np.datetime64)\n",
    "weath['month']=weath['date'].dt.month\n",
    "weath['day']=weath['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in range(len(weath)):\n",
    "    data.loc[((data['month']==weath['month'][c])&(data['day']==weath['day'][c]))&\n",
    "         (((data['hour']-weath['hour'][c])>=0)&((data['hour']-weath['hour'][c])<3)),'pressure']=weath['pressure'][c]\n",
    "    data.loc[((data['month']==weath['month'][c])&(data['day']==weath['day'][c]))&\n",
    "         (((data['hour']-weath['hour'][c])>=0)&((data['hour']-weath['hour'][c])<3)),'sea_pressure']=weath['sea_pressure'][c]\n",
    "    data.loc[((data['month']==weath['month'][c])&(data['day']==weath['day'][c]))&\n",
    "         (((data['hour']-weath['hour'][c])>=0)&((data['hour']-weath['hour'][c])<3)),'wind_direction']=weath['wind_direction'][c]\n",
    "    data.loc[((data['month']==weath['month'][c])&(data['day']==weath['day'][c]))&\n",
    "         (((data['hour']-weath['hour'][c])>=0)&((data['hour']-weath['hour'][c])<3)),'wind_speed']=weath['wind_speed'][c]\n",
    "    data.loc[((data['month']==weath['month'][c])&(data['day']==weath['day'][c]))&\n",
    "         (((data['hour']-weath['hour'][c])>=0)&((data['hour']-weath['hour'][c])<3)),'temperature']=weath['temperature'][c]\n",
    "    data.loc[((data['month']==weath['month'][c])&(data['day']==weath['day'][c]))&\n",
    "         (((data['hour']-weath['hour'][c])>=0)&((data['hour']-weath['hour'][c])<3)),'rel_humidity']=weath['rel_humidity'][c]\n",
    "    data.loc[((data['month']==weath['month'][c])&(data['day']==weath['day'][c]))&\n",
    "         (((data['hour']-weath['hour'][c])>=0)&((data['hour']-weath['hour'][c])<3)),'precipitation']=weath['precipitation'][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for c in data['time_window']:\n",
    "    c1=datetime.strptime(c[1:20], \"%Y-%m-%d %H:%M:%S\")\n",
    "    a.append((int(c1.hour)*60+int(c1.minute))/5)\n",
    "data['check']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data.to_csv('training_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2=pd.read_csv('5min_avg_travel_time_testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "b=[]\n",
    "for c in data2['time_window']:\n",
    "    c1=datetime.strptime(c[1:20], \"%Y-%m-%d %H:%M:%S\")\n",
    "    a.append(c1)\n",
    "data2['date']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2['month']=data2['date'].dt.month\n",
    "data2['day']=data2['date'].dt.day\n",
    "data2['hour']=data2['date'].dt.hour\n",
    "data2['time']=data2['date'].dt.minute\n",
    "data2['weekday']=data2['date'].dt.weekday+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2.insert(3, \"t1\", 0)\n",
    "data2.insert(4, \"t2\", 0)\n",
    "data2.insert(5, \"t3\", 0)\n",
    "data2.insert(6, \"deltat1\", 0)\n",
    "data2.insert(7, \"deltat2\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A2test=data2.loc[(data2['intersection_id']=='A')&(data2['tollgate_id']==2)]\n",
    "A3test=data2.loc[(data2['intersection_id']=='A')&(data2['tollgate_id']==3)]\n",
    "B1test=data2.loc[(data2['intersection_id']=='B')&(data2['tollgate_id']==1)]\n",
    "B3test=data2.loc[(data2['intersection_id']=='B')&(data2['tollgate_id']==3)]\n",
    "C1test=data2.loc[(data2['intersection_id']=='C')&(data2['tollgate_id']==1)]\n",
    "C3test=data2.loc[(data2['intersection_id']=='C')&(data2['tollgate_id']==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d=[A2,A3,B1,B3,C1,C3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d1=[A2test,A3test,B1test,B3test,C1test,C3test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1=timedelta(days=0,minutes=5)\n",
    "time2=timedelta(days=0,minutes=10)\n",
    "time3=timedelta(days=0,minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data2 in d1:\n",
    "    for c in (data2.index):\n",
    "        data2.loc[(data2[\"date\"])==(data2[\"date\"][c]+time1),'t1']=data2[\"avg_travel_time\"][c]\n",
    "        data2.loc[(data2[\"date\"])==(data2[\"date\"][c]+time2),'t2']=data2[\"avg_travel_time\"][c]\n",
    "        data2.loc[(data2[\"date\"])==(data2[\"date\"][c]+time3),'t3']=data2[\"avg_travel_time\"][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for count in range(6):\n",
    "    for c in range(7):\n",
    "        for c1 in range(24):\n",
    "            d1[count].loc[(d1[count]['weekday']==c) & (d1[count]['hour']==c1) & (d1[count]['t1']==0),'t1']=d[count].loc[(d[count]['weekday']==c) & (d[count]['hour']==c1) & (d[count]['t1']!=0)]['t1'].mean()\n",
    "            d1[count].loc[(d1[count]['weekday']==c) & (d1[count]['hour']==c1) & (d1[count]['t2']==0),'t2']=d[count].loc[(d[count]['weekday']==c) & (d[count]['hour']==c1) & (d[count]['t2']!=0)]['t2'].mean()\n",
    "            d1[count].loc[(d1[count]['weekday']==c) & (d1[count]['hour']==c1) & (d1[count]['t3']==0),'t3']=d[count].loc[(d[count]['weekday']==c) & (d[count]['hour']==c1) & (d[count]['t3']!=0)]['t3'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2=pd.concat(d1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2['deltat1']=data2['t1']-data2['t2']\n",
    "data2['deltat2']=data2['t2']-data2['t3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "month=[10]*350\n",
    "starting_time=[]\n",
    "hours=[]\n",
    "minute=[]\n",
    "day=[]\n",
    "weekday=[]\n",
    "datetime(2016,4,16,23,55)\n",
    "for c in range(25,32):\n",
    "    for c1 in [8,9,10,17,18,19]:\n",
    "        for c2 in range(0,56,5):\n",
    "            if (c1==10 or c1==19):\n",
    "                t=datetime(2016,10,c,c1,0,0)\n",
    "                weekday.append(t.weekday()+1)\n",
    "                t=t.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                starting_time.append(t)\n",
    "                hours.append(c1)\n",
    "                minute.append(c2)\n",
    "                day.append(c)\n",
    "                break\n",
    "            else:\n",
    "                t=datetime(2016,10,c,c1,c2,0)\n",
    "                weekday.append(t.weekday()+1)\n",
    "                t=t.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                starting_time.append(t)\n",
    "                hours.append(c1)\n",
    "                minute.append(c2)\n",
    "                day.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection_id=['A']*350\n",
    "tollgate_id=[2]*350\n",
    "travel_time=[0]*350\n",
    "cc={\n",
    "    'intersection_id':intersection_id,\n",
    "    'tollgate_id':tollgate_id,\n",
    "    'travel_time':travel_time,\n",
    "    'starting_time':starting_time,\n",
    "    'weekday':weekday,\n",
    "    'month':month,\n",
    "    'day':day,\n",
    "    'hours':hours,\n",
    "    'minute':minute\n",
    "   }\n",
    "A2pre=pd.DataFrame(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection_id=['A']*350\n",
    "tollgate_id=[3]*350\n",
    "travel_time=[0]*350\n",
    "cc={\n",
    "    'intersection_id':intersection_id,\n",
    "    'tollgate_id':tollgate_id,\n",
    "    'travel_time':travel_time,\n",
    "    'starting_time':starting_time,\n",
    "    'weekday':weekday,\n",
    "    'month':month,\n",
    "    'day':day,\n",
    "    'hours':hours,\n",
    "    'minute':minute\n",
    "   }\n",
    "A3pre=pd.DataFrame(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection_id=['B']*350\n",
    "tollgate_id=[1]*350\n",
    "travel_time=[0]*350\n",
    "cc={\n",
    "    'intersection_id':intersection_id,\n",
    "    'tollgate_id':tollgate_id,\n",
    "    'travel_time':travel_time,\n",
    "    'starting_time':starting_time,\n",
    "    'weekday':weekday,\n",
    "    'month':month,\n",
    "    'day':day,\n",
    "    'hours':hours,\n",
    "    'minute':minute\n",
    "   }\n",
    "B1pre=pd.DataFrame(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intersection_id=['B']*350\n",
    "tollgate_id=[3]*350\n",
    "travel_time=[0]*350\n",
    "cc={\n",
    "    'intersection_id':intersection_id,\n",
    "    'tollgate_id':tollgate_id,\n",
    "    'travel_time':travel_time,\n",
    "    'starting_time':starting_time,\n",
    "    'weekday':weekday,\n",
    "    'month':month,\n",
    "    'day':day,\n",
    "    'hours':hours,\n",
    "    'minute':minute\n",
    "   }\n",
    "B3pre=pd.DataFrame(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection_id=['C']*350\n",
    "tollgate_id=[1]*350\n",
    "travel_time=[0]*350\n",
    "cc={\n",
    "    'intersection_id':intersection_id,\n",
    "    'tollgate_id':tollgate_id,\n",
    "    'travel_time':travel_time,\n",
    "    'starting_time':starting_time,\n",
    "    'weekday':weekday,\n",
    "    'month':month,\n",
    "    'day':day,\n",
    "    'hours':hours,\n",
    "    'minute':minute\n",
    "   }\n",
    "C1pre=pd.DataFrame(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersection_id=['C']*350\n",
    "tollgate_id=[3]*350\n",
    "travel_time=[0]*350\n",
    "cc={\n",
    "    'intersection_id':intersection_id,\n",
    "    'tollgate_id':tollgate_id,\n",
    "    'travel_time':travel_time,\n",
    "    'starting_time':starting_time,\n",
    "    'weekday':weekday,\n",
    "    'month':month,\n",
    "    'day':day,\n",
    "    'hours':hours,\n",
    "    'minute':minute\n",
    "   }\n",
    "C3pre=pd.DataFrame(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d=[A2,A3,B1,B3,C1,C3]\n",
    "d1=[A2test,A3test,B1test,B3test,C1test,C3test]\n",
    "d2=[A2pre,A3pre,B1pre,B3pre,C1pre,C3pre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time1=timedelta(days=0,minutes=5)\n",
    "time2=timedelta(days=0,minutes=10)\n",
    "time3=timedelta(days=0,minutes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for count, pre in enumerate(d2):\n",
    "    pre.insert(3, \"t1\", 0.00)\n",
    "    pre.insert(4, \"t2\", 0.00)\n",
    "    pre.insert(5, \"t3\", 0.00)\n",
    "    pre.insert(6, \"deltat1\", 0.00)\n",
    "    pre.insert(7, \"deltat2\", 0.00)\n",
    "    pre['starting_time']=pre['starting_time'].astype(np.datetime64)\n",
    "    for c in d1[count].index:\n",
    "        pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&((pre[\"starting_time\"])==(d1[count][\"date\"][c]+time1)),'t1']=d1[count][\"avg_travel_time\"][c]\n",
    "        pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&((pre[\"starting_time\"])==(d1[count][\"date\"][c]+time1)),'t2']=d1[count][\"t1\"][c]\n",
    "        pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&((pre[\"starting_time\"])==(d1[count][\"date\"][c]+time1)),'t3']=d1[count][\"t2\"][c]\n",
    "\n",
    "        pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&((pre[\"starting_time\"])==(d1[count][\"date\"][c]+time2)),'t2']=d1[count][\"avg_travel_time\"][c]\n",
    "        pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&((pre[\"starting_time\"])==(d1[count][\"date\"][c]+time2)),'t3']=d1[count][\"t1\"][c]\n",
    "\n",
    "        pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&((pre[\"starting_time\"])==(d1[count][\"date\"][c]+time3)),'t3']=d1[count][\"avg_travel_time\"][c]\n",
    "        \n",
    "    noise=pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&(pre[\"t1\"]==0)]\n",
    "    for c in noise.index:\n",
    "        pre.loc[(((pre[\"hours\"]==noise['hours'][c]))&\n",
    "                (pre[\"minute\"]==0))&\n",
    "                (pre[\"t1\"]==0)&\n",
    "                (pre[\"weekday\"]==noise['weekday'][c]),'t1']=d[count].loc[(d[count][\"hour\"]==noise[\"hours\"][c])&(d[count][\"time\"]==noise[\"minute\"][c])&(d[count][\"weekday\"]==noise['weekday'][c])]['t1'].mean()\n",
    "        pre.loc[(((pre[\"hours\"]==noise['hours'][c]))&\n",
    "            (pre[\"minute\"]==0))&\n",
    "            (pre[\"t1\"].isnull())&\n",
    "            (pre[\"weekday\"]==noise['weekday'][c]),'t1']=d[count].loc[(d[count][\"hour\"]==noise[\"hours\"][c])&(d[count][\"time\"]==noise[\"minute\"][c])]['t1'].mean()\n",
    "    noise=pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&(pre[\"t2\"]==0)]\n",
    "    for c in noise.index:\n",
    "        pre.loc[(((pre[\"hours\"]==noise['hours'][c]))&\n",
    "                (pre[\"minute\"]==0))&\n",
    "                (pre[\"t2\"]==0)&\n",
    "                (pre[\"weekday\"]==noise['weekday'][c]),'t2']=d[count].loc[(d[count][\"hour\"]==noise[\"hours\"][c])&(d[count][\"time\"]==noise[\"minute\"][c])&(d[count][\"weekday\"]==noise['weekday'][c])]['t2'].mean()\n",
    "        pre.loc[(((pre[\"hours\"]==noise['hours'][c]))&\n",
    "            (pre[\"minute\"]==0))&\n",
    "            (pre[\"t2\"].isnull())&\n",
    "            (pre[\"weekday\"]==noise['weekday'][c]),'t2']=d[count].loc[(d[count][\"hour\"]==noise[\"hours\"][c])&(d[count][\"time\"]==noise[\"minute\"][c])]['t2'].mean()\n",
    "    noise=pre.loc[(((pre[\"hours\"]==8)|(pre[\"hours\"]==17))&(pre[\"minute\"]==0))&(pre[\"t3\"]==0)]\n",
    "    for c in noise.index:\n",
    "        pre.loc[(((pre[\"hours\"]==noise['hours'][c]))&\n",
    "                (pre[\"minute\"]==0))&\n",
    "                (pre[\"t3\"]==0)&\n",
    "                (pre[\"weekday\"]==noise['weekday'][c]),'t3']=d[count].loc[(d[count][\"hour\"]==noise[\"hours\"][c])&(d[count][\"time\"]==noise[\"minute\"][c])&(d[count][\"weekday\"]==noise['weekday'][c])]['t3'].mean()\n",
    "        pre.loc[(((pre[\"hours\"]==noise['hours'][c]))&\n",
    "            (pre[\"minute\"]==0))&\n",
    "            (pre[\"t3\"].isnull())&\n",
    "            (pre[\"weekday\"]==noise['weekday'][c]),'t3']=d[count].loc[(d[count][\"hour\"]==noise[\"hours\"][c])&(d[count][\"time\"]==noise[\"minute\"][c])]['t3'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_data=pd.concat(d2,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_data['travel_time']=pre_data['travel_time'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_data['deltat1']=pre_data['t1']-pre_data['t2']\n",
    "pre_data['deltat2']=pre_data['t2']-pre_data['t3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=[]\n",
    "for c in pre_data['starting_time']:\n",
    "    a.append((int(c.hour)*60+int(c.minute))/5)\n",
    "pre_data['check']=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_data.insert(15,\"pressure\", 0)\n",
    "pre_data.insert(16,\"sea_pressure\", 0)\n",
    "pre_data.insert(17,\"wind_direction\", 0)\n",
    "pre_data.insert(18,\"wind_speed\", 0)\n",
    "pre_data.insert(19,\"temperature\", 0)\n",
    "pre_data.insert(20,\"rel_humidity\", 0)\n",
    "pre_data.insert(21,\"precipitation\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weath=pd.read_csv('./weather (table 7)_2.csv')\n",
    "weath['date']=weath['date'].astype(np.datetime64)\n",
    "weath['month']=weath['date'].dt.month\n",
    "weath['day']=weath['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M=[]\n",
    "H=[]\n",
    "day=[]\n",
    "month=[]\n",
    "for c in weath[\"date\"]:\n",
    "    day.append(int(c.strftime(\"%d\")))\n",
    "    month.append(int(c.strftime(\"%m\")))\n",
    "weath[\"month\"]=month\n",
    "weath[\"day\"]=day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in range(len(weath)):\n",
    "    pre_data.loc[((data['month']==weath['month'][c])&(pre_data['day']==weath['day'][c]))&\n",
    "         (((pre_data['hours']-weath['hour'][c])>=0)&((pre_data['hours']-weath['hour'][c])<3)),'pressure']=weath['pressure'][c]\n",
    "    pre_data.loc[((pre_data['month']==weath['month'][c])&(pre_data['day']==weath['day'][c]))&\n",
    "         (((pre_data['hours']-weath['hour'][c])>=0)&((pre_data['hours']-weath['hour'][c])<3)),'sea_pressure']=weath['sea_pressure'][c]\n",
    "    pre_data.loc[((pre_data['month']==weath['month'][c])&(pre_data['day']==weath['day'][c]))&\n",
    "         (((pre_data['hours']-weath['hour'][c])>=0)&((pre_data['hours']-weath['hour'][c])<3)),'wind_direction']=weath['wind_direction'][c]\n",
    "    pre_data.loc[((pre_data['month']==weath['month'][c])&(pre_data['day']==weath['day'][c]))&\n",
    "         (((pre_data['hours']-weath['hour'][c])>=0)&((pre_data['hours']-weath['hour'][c])<3)),'wind_speed']=weath['wind_speed'][c]\n",
    "    pre_data.loc[((pre_data['month']==weath['month'][c])&(pre_data['day']==weath['day'][c]))&\n",
    "         (((pre_data['hours']-weath['hour'][c])>=0)&((pre_data['hours']-weath['hour'][c])<3)),'temperature']=weath['temperature'][c]\n",
    "    pre_data.loc[((pre_data['month']==weath['month'][c])&(pre_data['day']==weath['day'][c]))&\n",
    "         (((pre_data['hours']-weath['hour'][c])>=0)&((pre_data['hours']-weath['hour'][c])<3)),'rel_humidity']=weath['rel_humidity'][c]\n",
    "    pre_data.loc[((pre_data['month']==weath['month'][c])&(pre_data['day']==weath['day'][c]))&\n",
    "         (((pre_data['hours']-weath['hour'][c])>=0)&((pre_data['hours']-weath['hour'][c])<3)),'precipitation']=weath['precipitation'][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_data.to_csv('predict_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end data preparation\n"
     ]
    }
   ],
   "source": [
    "print ('end data preparation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
